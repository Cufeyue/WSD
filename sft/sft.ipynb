{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Dict, Union, Any\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from datasets import load_dataset\n",
    "from peft import AutoPeftModelForCausalLM, LoraConfig\n",
    "from transformers import(\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    HfArgumentParser,\n",
    "    set_seed,\n",
    "    TrainingArguments\n",
    ")\n",
    "from trl import(\n",
    "    DataCollatorForCompletionOnlyLM,\n",
    "    SFTTrainer,\n",
    "    SFTConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)\n",
    "\n",
    "checkpoint = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"self_attn.q_proj\",\n",
    "        \"self_attn.k_proj\",\n",
    "        \"self_attn.v_proj\",\n",
    "        \"self_attn.o_proj\",\n",
    "        \"mlp.gate_proj\",\n",
    "        \"mlp.up_proj\",\n",
    "        \"mlp.down_proj\",\n",
    "    ],\n",
    "    lora_dropout=0.0,\n",
    "    bias=\"none\",\n",
    "    task_type='CAUSAL_LM'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    checkpoint,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype='auto',\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=\"sdpa\",\n",
    "    use_cache=False\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "# tokenizer.pad_token\n",
    "# tokenizer.chat_template \n",
    "# tokenizer.padding_side = \"right\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.1836, -0.2617, -0.0718,  ...,  0.0825,  0.0188,  0.0286],\n",
       "       device='cuda:0', dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.layers[0].self_attn.q_proj.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a18d16dd79748269b919e8d35cac205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "apply chat template (num_proc=64):   0%|          | 0/50661 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"bigcode/self-oss-instruct-sc2-exec-filter-50k\",\n",
    "    split=\"train\",\n",
    ") \n",
    "\n",
    "def process(example):\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': example['instruction']},\n",
    "        {'role': 'assistant', 'content': example['response']}\n",
    "    ]\n",
    "    return {'text': tokenizer.apply_chat_template(messages, tokenize=False)}\n",
    "\n",
    "dataset = dataset.map(process, num_proc=64, \n",
    "                          remove_columns=dataset.column_names,\n",
    "                          desc=\"apply chat template\")\n",
    "dataset = dataset.train_test_split(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac47e4fba00640e394d5f8f99dcbcc7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/51 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce394c668c747aaa038eb8e2caa6e7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "746381"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].to_json('./datasets/sft/train.json', orient=\"records\", lines=True)\n",
    "dataset['test'].to_json('./datasets/sft/val.json', orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bb5a0e010a4c7c9b7adbd7e46d3528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9a520c1ca6d49dfad8b5df56f757d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating valid split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 50154\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 507\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\"train\": \"./datasets/sft/train.json\", \n",
    "                \"valid\": \"./datasets/sft/val.json\"}\n",
    ")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sftconfig import SFTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "PyTorch: setting up devices\n",
      "Using auto half precision backend\n"
     ]
    }
   ],
   "source": [
    "sft_config = SFTConfig()\n",
    "\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template='<|im_start|>assistant\\n', instruction_template='<|im_start|>user\\n', tokenizer=tokenizer)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=sft_config,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"valid\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=collator,\n",
    "    peft_config=peft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiny_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
